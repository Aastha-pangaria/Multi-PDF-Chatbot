{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multpile pdf reading Chat-bot\n"
      ],
      "metadata": {
        "id": "pJ7FvmANJ7Rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q streamlit pymupdf chromadb pyngrok faiss-cpu sentence-transformers mistralai==0.4.2 python-docx\n",
        "\n",
        "# Configuring ngrok authtoken\n",
        "!ngrok config add-authtoken 2xDRF1RvT6YJDp4CJkWMzyp1I65_6yk76D4JxHm1do76eWGb2\n",
        "\n",
        "# Killing previous processes\n",
        "!pkill -f streamlit || echo \"No old Streamlit process\"\n",
        "!pkill -f ngrok || echo \"No old ngrok process\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQDVTG6ZvH_J",
        "outputId": "74ef33e7-4fcc-4b0e-aff9-db4d3d0ed4dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import fitz  # PyMuPDF for PDF\n",
        "from docx import Document  # For DOCX\n",
        "import tempfile\n",
        "import os\n",
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "\n",
        "st.set_page_config(page_title=\"RAG Multi-Document Chatbot\", layout=\"wide\")\n",
        "st.title(\"🤖 RAG Multi-Document Chatbot\")\n",
        "\n",
        "# Sidebar for API key and file uploads\n",
        "api_key = st.sidebar.text_input(\"🔑 Enter Mistral API Key\", type=\"password\")\n",
        "uploaded_files = st.sidebar.file_uploader(\"📄 Upload Documents (PDF, DOCX, TXT)\",\n",
        "                                         type=[\"pdf\", \"docx\", \"txt\"],\n",
        "                                         accept_multiple_files=True)\n",
        "\n",
        "# Session state\n",
        "if \"db\" not in st.session_state:\n",
        "    st.session_state.db = None\n",
        "if \"chunks\" not in st.session_state:\n",
        "    st.session_state.chunks = []\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "if \"collection_name\" not in st.session_state:\n",
        "    st.session_state.collection_name = \"doc_chunks\"\n",
        "\n",
        "# Function to extract text from different file types\n",
        "def extract_text(file, file_type):\n",
        "    try:\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=f\".{file_type}\") as tmp:\n",
        "            tmp.write(file.getbuffer())\n",
        "            tmp_path = tmp.name\n",
        "\n",
        "        if file_type == \"pdf\":\n",
        "            with fitz.open(tmp_path) as doc:\n",
        "                if len(doc) == 0:\n",
        "                    st.error(f\"PDF {file.name} is empty or corrupted.\")\n",
        "                    return \"\"\n",
        "                text = \"\".join(page.get_text() for page in doc)\n",
        "        elif file_type == \"docx\":\n",
        "            doc = Document(tmp_path)\n",
        "            text = \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
        "        elif file_type == \"txt\":\n",
        "            with open(tmp_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                text = f.read()\n",
        "        else:\n",
        "            st.error(f\"Unsupported file type: {file_type}\")\n",
        "            return \"\"\n",
        "\n",
        "        os.remove(tmp_path)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error processing {file.name}: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "# Document processing\n",
        "if uploaded_files and api_key and st.sidebar.button(\"Process Documents\"):\n",
        "    with st.spinner(\"Processing Documents...\"):\n",
        "        st.session_state.chunks = []\n",
        "        for i, file in enumerate(uploaded_files):\n",
        "            file_type = file.name.split(\".\")[-1].lower()\n",
        "            st.info(f\"Extracting text from {file_type.upper()} {i+1}/{len(uploaded_files)}: {file.name}\")\n",
        "            text = extract_text(file, file_type)\n",
        "            if not text:\n",
        "                continue  # Skip to the next file if text extraction fails\n",
        "            # Chunking: 2000 chars per chunk\n",
        "            chunks = [text[i:i+2000] for i in range(0, len(text), 2000)]\n",
        "            st.session_state.chunks.extend(chunks)\n",
        "\n",
        "        if not st.session_state.chunks:\n",
        "            st.error(\"No valid content extracted from documents.\")\n",
        "        else:\n",
        "            st.info(f\"Total chunks to embed: {len(st.session_state.chunks)}\")\n",
        "            # Embeddings\n",
        "            embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "            embeddings = embedder.encode(st.session_state.chunks, show_progress_bar=True)\n",
        "            # ChromaDB (persistent storage)\n",
        "            client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "            if st.session_state.collection_name in [col.name for col in client.list_collections()]:\n",
        "                client.delete_collection(st.session_state.collection_name)\n",
        "            collection = client.create_collection(st.session_state.collection_name)\n",
        "            for i, (chunk, emb) in enumerate(zip(st.session_state.chunks, embeddings)):\n",
        "                collection.add(documents=[chunk], embeddings=[emb.tolist()], ids=[str(i)])\n",
        "            st.session_state.db = collection\n",
        "            st.success(f\"Processed {len(uploaded_files)} documents and indexed {len(st.session_state.chunks)} chunks.\")\n",
        "\n",
        "# Chat interface\n",
        "if api_key and st.session_state.db:\n",
        "    for role, msg in st.session_state.history:\n",
        "        with st.chat_message(role):\n",
        "            st.write(msg)\n",
        "    user_input = st.chat_input(\"Ask a question about your documents...\")\n",
        "    if user_input:\n",
        "        try:\n",
        "            embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "            # Fix: Extract the single embedding vector by taking the first element\n",
        "            q_emb = embedder.encode([user_input]).tolist()[0]\n",
        "            results = st.session_state.db.query(query_embeddings=[q_emb], n_results=4)\n",
        "            context = \"\\n\\n\".join(results[\"documents\"][0])\n",
        "            client = MistralClient(api_key=api_key)\n",
        "            messages = [\n",
        "                ChatMessage(role=\"system\", content=\"You are a helpful assistant. Use the provided context from documents to answer.\"),\n",
        "                ChatMessage(role=\"user\", content=f\"Context:\\n{context}\\n\\nQuestion: {user_input}\")\n",
        "            ]\n",
        "            response = client.chat(model=\"mistral-small-latest\", messages=messages)\n",
        "            answer = response.choices[0].message.content\n",
        "            st.session_state.history.append((\"user\", user_input))\n",
        "            st.session_state.history.append((\"assistant\", answer))\n",
        "            # Limit history to last 50 entries (25 exchanges)\n",
        "            if len(st.session_state.history) > 50:\n",
        "                st.session_state.history = st.session_state.history[-50:]\n",
        "            st.rerun()\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error generating response: {str(e)}\")\n",
        "elif not api_key:\n",
        "    st.info(\"Enter your Mistral API key in the sidebar.\")\n",
        "elif not uploaded_files:\n",
        "    st.info(\"Upload documents (PDF, DOCX, TXT) and click 'Process Documents'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePHMZ0mnUCSf",
        "outputId": "30950676-220f-4bb2-bca7-ade6356d1ff1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Start Streamlit\n",
        "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\"])\n",
        "\n",
        "# Wait for Streamlit to start\n",
        "for _ in range(10):\n",
        "    try:\n",
        "        requests.get(\"http://localhost:8501\")\n",
        "        break\n",
        "    except:\n",
        "        time.sleep(1)\n",
        "else:\n",
        "    print(\"Streamlit failed to start\")\n",
        "    process.terminate()\n",
        "    exit(1)\n",
        "\n",
        "# Start ngrok\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"🌐 Your app is live at: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok: {str(e)}\")\n",
        "    process.terminate()\n",
        "    exit(1)\n",
        "\n",
        "import atexit\n",
        "atexit.register(process.terminate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "i6q4rIvCgKZJ",
        "outputId": "bcabfe0c-7922-49ae-d999-b6c768165de0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌐 Your app is live at: NgrokTunnel: \"https://73d8-34-133-229-21.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Popen.terminate of <Popen: returncode: None args: ['streamlit', 'run', 'app.py', '--server.port...>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>subprocess.Popen.terminate</b><br/>def terminate()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/lib/python3.11/subprocess.py</a>Terminate the process with SIGTERM\n",
              "            </pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 2208);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}